name: Setup & Deploy Test Environment

# Provisions all AWS infrastructure from scratch and deploys the application.
# Self-healing: skips resources that already exist.

on:
  workflow_dispatch: {}

# Prevent parallel setup runs on the same environment
concurrency:
  group: setup-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
  ENVIRONMENT: test
  PROJECT_NAME: shoreexplorer
  BACKEND_ECR_REPO: shoreexplorer-backend
  FRONTEND_ECR_REPO: shoreexplorer-frontend

jobs:
  setup-and-deploy-test:
    name: Setup & Deploy Test
    runs-on: ubuntu-latest
    environment: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set variables
        id: vars
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_BASE="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          GIT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
          IMAGE_TAG="${ENVIRONMENT}-${GIT_SHA}"

          echo "account_id=${ACCOUNT_ID}" >> "$GITHUB_OUTPUT"
          echo "ecr_base=${ECR_BASE}" >> "$GITHUB_OUTPUT"
          echo "image_tag=${IMAGE_TAG}" >> "$GITHUB_OUTPUT"

      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      #  INFRASTRUCTURE PROVISIONING
      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

      # ‚îÄ‚îÄ 1. ECR Repositories (shared) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ECR repositories
        run: |
          echo "üì¶ Ensuring ECR repositories exist..."
          for REPO in "$BACKEND_ECR_REPO" "$FRONTEND_ECR_REPO"; do
            if aws ecr describe-repositories --repository-names "$REPO" --region "$AWS_REGION" &>/dev/null; then
              echo "  ‚è≠Ô∏è  ECR repo exists: $REPO"
            else
              aws ecr create-repository --repository-name "$REPO" --region "$AWS_REGION" \
                --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE \
                --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value=shared \
                --no-cli-pager
              echo "  ‚úÖ Created ECR repo: $REPO"
            fi

            # Set lifecycle policy
            aws ecr put-lifecycle-policy --repository-name "$REPO" --region "$AWS_REGION" \
              --lifecycle-policy-text '{"rules":[{"rulePriority":1,"description":"Keep last 10","selection":{"tagStatus":"any","countType":"imageCountMoreThan","countNumber":10},"action":{"type":"expire"}}]}' \
              --no-cli-pager >/dev/null 2>&1 || true
          done

      # ‚îÄ‚îÄ 2. VPC & Networking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create networking
        id: networking
        run: |
          echo "üåê Provisioning networking..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          VPC_CIDR="10.0.0.0/16"
          AZ1="${AWS_REGION}a"
          AZ2="${AWS_REGION}b"

          # VPC
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=${APP_NAME}-vpc" \
            --query "Vpcs[0].VpcId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            VPC_ID=$(aws ec2 create-vpc --cidr-block "$VPC_CIDR" \
              --tag-specifications "ResourceType=vpc,Tags=[{Key=Name,Value=${APP_NAME}-vpc},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "Vpc.VpcId" --output text --region "$AWS_REGION")
            aws ec2 modify-vpc-attribute --vpc-id "$VPC_ID" --enable-dns-hostnames '{"Value":true}' --region "$AWS_REGION"
            aws ec2 modify-vpc-attribute --vpc-id "$VPC_ID" --enable-dns-support '{"Value":true}' --region "$AWS_REGION"
            echo "  ‚úÖ Created VPC: $VPC_ID"
          else
            echo "  ‚è≠Ô∏è  VPC exists: $VPC_ID"
          fi

          # Internet Gateway
          IGW_ID=$(aws ec2 describe-internet-gateways \
            --filters "Name=tag:Name,Values=${APP_NAME}-igw" \
            --query "InternetGateways[0].InternetGatewayId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$IGW_ID" == "None" || -z "$IGW_ID" ]]; then
            IGW_ID=$(aws ec2 create-internet-gateway \
              --tag-specifications "ResourceType=internet-gateway,Tags=[{Key=Name,Value=${APP_NAME}-igw},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "InternetGateway.InternetGatewayId" --output text --region "$AWS_REGION")
            aws ec2 attach-internet-gateway --internet-gateway-id "$IGW_ID" --vpc-id "$VPC_ID" --region "$AWS_REGION"
            echo "  ‚úÖ Created IGW: $IGW_ID"
          else
            echo "  ‚è≠Ô∏è  IGW exists: $IGW_ID"
          fi

          # Helper function for subnet creation
          create_subnet() {
            local NAME="$1" CIDR="$2" AZ="$3" MAP_PUBLIC="$4"
            local SID
            SID=$(aws ec2 describe-subnets \
              --filters "Name=tag:Name,Values=$NAME" "Name=vpc-id,Values=$VPC_ID" \
              --query "Subnets[0].SubnetId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$SID" == "None" || -z "$SID" ]]; then
              SID=$(aws ec2 create-subnet --vpc-id "$VPC_ID" --cidr-block "$CIDR" --availability-zone "$AZ" \
                --tag-specifications "ResourceType=subnet,Tags=[{Key=Name,Value=$NAME},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
                --query "Subnet.SubnetId" --output text --region "$AWS_REGION")
              if [[ "$MAP_PUBLIC" == "true" ]]; then
                aws ec2 modify-subnet-attribute --subnet-id "$SID" --map-public-ip-on-launch --region "$AWS_REGION"
              fi
              echo "  ‚úÖ Created subnet: $NAME ($SID)" >&2
            else
              echo "  ‚è≠Ô∏è  Subnet exists: $NAME ($SID)" >&2
            fi
            echo "$SID"
          }

          PUB1=$(create_subnet "${APP_NAME}-public-1" "10.0.1.0/24" "$AZ1" "true")
          PUB2=$(create_subnet "${APP_NAME}-public-2" "10.0.2.0/24" "$AZ2" "true")
          create_subnet "${APP_NAME}-private-1" "10.0.3.0/24" "$AZ1" "false" >/dev/null
          create_subnet "${APP_NAME}-private-2" "10.0.4.0/24" "$AZ2" "false" >/dev/null

          # Route Table
          RT_ID=$(aws ec2 describe-route-tables \
            --filters "Name=tag:Name,Values=${APP_NAME}-public-rt" "Name=vpc-id,Values=$VPC_ID" \
            --query "RouteTables[0].RouteTableId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$RT_ID" == "None" || -z "$RT_ID" ]]; then
            RT_ID=$(aws ec2 create-route-table --vpc-id "$VPC_ID" \
              --tag-specifications "ResourceType=route-table,Tags=[{Key=Name,Value=${APP_NAME}-public-rt},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "RouteTable.RouteTableId" --output text --region "$AWS_REGION")
            aws ec2 create-route --route-table-id "$RT_ID" --destination-cidr-block "0.0.0.0/0" --gateway-id "$IGW_ID" --region "$AWS_REGION" >/dev/null
            echo "  ‚úÖ Created route table: $RT_ID"
          else
            echo "  ‚è≠Ô∏è  Route table exists: $RT_ID"
          fi

          # Associate subnets
          for SID in "$PUB1" "$PUB2"; do
            ASSOC=$(aws ec2 describe-route-tables \
              --filters "Name=association.subnet-id,Values=$SID" "Name=route-table-id,Values=$RT_ID" \
              --query "RouteTables[0].RouteTableId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$ASSOC" == "None" || -z "$ASSOC" ]]; then
              aws ec2 associate-route-table --subnet-id "$SID" --route-table-id "$RT_ID" --region "$AWS_REGION" >/dev/null
            fi
          done

          # Security Groups
          create_sg() {
            local SG_NAME="$1" DESC="$2"
            local SGID
            SGID=$(aws ec2 describe-security-groups \
              --filters "Name=group-name,Values=$SG_NAME" "Name=vpc-id,Values=$VPC_ID" \
              --query "SecurityGroups[0].GroupId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$SGID" == "None" || -z "$SGID" ]]; then
              SGID=$(aws ec2 create-security-group --group-name "$SG_NAME" --description "$DESC" --vpc-id "$VPC_ID" \
                --tag-specifications "ResourceType=security-group,Tags=[{Key=Name,Value=$SG_NAME},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
                --query "GroupId" --output text --region "$AWS_REGION")
              echo "  ‚úÖ Created SG: $SG_NAME ($SGID)" >&2
            else
              echo "  ‚è≠Ô∏è  SG exists: $SG_NAME ($SGID)" >&2
            fi
            echo "$SGID"
          }

          ALB_SG_ID=$(create_sg "${APP_NAME}-alb-sg" "ALB security group")
          ECS_SG_ID=$(create_sg "${APP_NAME}-ecs-sg" "ECS tasks security group")

          # SG rules (idempotent)
          for PORT in 80 443; do
            aws ec2 authorize-security-group-ingress --group-id "$ALB_SG_ID" \
              --protocol tcp --port "$PORT" --cidr "0.0.0.0/0" --region "$AWS_REGION" 2>/dev/null || true
          done
          aws ec2 authorize-security-group-ingress --group-id "$ECS_SG_ID" \
            --protocol tcp --port 8001 --source-group "$ALB_SG_ID" --region "$AWS_REGION" 2>/dev/null || true
          aws ec2 authorize-security-group-ingress --group-id "$ECS_SG_ID" \
            --protocol tcp --port 8080 --source-group "$ALB_SG_ID" --region "$AWS_REGION" 2>/dev/null || true

          # Outputs
          echo "vpc_id=${VPC_ID}" >> "$GITHUB_OUTPUT"
          echo "pub_subnet_1=${PUB1}" >> "$GITHUB_OUTPUT"
          echo "pub_subnet_2=${PUB2}" >> "$GITHUB_OUTPUT"
          echo "alb_sg_id=${ALB_SG_ID}" >> "$GITHUB_OUTPUT"
          echo "ecs_sg_id=${ECS_SG_ID}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 3. Secrets Manager ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create secrets
        id: secrets
        env:
          GROQ_API_KEY: ${{ secrets.TEST_GROQ_API_KEY }}
        run: |
          echo "üîê Ensuring secrets exist..."
          SECRET_NAME="${PROJECT_NAME}-${ENVIRONMENT}-secrets"

          if aws secretsmanager describe-secret --secret-id "$SECRET_NAME" --region "$AWS_REGION" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Secret exists: $SECRET_NAME"
            # Update if GROQ_API_KEY is provided
            if [[ -n "${GROQ_API_KEY:-}" ]]; then
              aws secretsmanager update-secret --secret-id "$SECRET_NAME" \
                --secret-string "{\"GROQ_API_KEY\":\"${GROQ_API_KEY}\"}" \
                --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
            fi
          else
            aws secretsmanager create-secret --name "$SECRET_NAME" \
              --description "ShoreExplorer ${ENVIRONMENT} environment secrets" \
              --secret-string "{\"GROQ_API_KEY\":\"${GROQ_API_KEY:-placeholder}\"}" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created secret: $SECRET_NAME"
          fi

          SECRET_ARN=$(aws secretsmanager describe-secret --secret-id "$SECRET_NAME" \
            --query "ARN" --output text --region "$AWS_REGION")
          echo "secret_arn=${SECRET_ARN}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 4. IAM Roles ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create IAM roles
        run: |
          echo "üîë Ensuring IAM roles exist..."
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          SECRET_ARN="${{ steps.secrets.outputs.secret_arn }}"

          TRUST_POLICY='{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"ecs-tasks.amazonaws.com"},"Action":"sts:AssumeRole"}]}'

          # Execution role
          EXEC_ROLE="${APP_NAME}-ecs-task-execution-role"
          if aws iam get-role --role-name "$EXEC_ROLE" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Role exists: $EXEC_ROLE"
          else
            aws iam create-role --role-name "$EXEC_ROLE" --assume-role-policy-document "$TRUST_POLICY" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" --no-cli-pager >/dev/null
            aws iam attach-role-policy --role-name "$EXEC_ROLE" \
              --policy-arn "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
            echo "  ‚úÖ Created role: $EXEC_ROLE"
          fi

          # Execution role inline policies (idempotent put)
          cat > /tmp/exec-policy.json <<POLICY
          {"Version":"2012-10-17","Statement":[
            {"Effect":"Allow","Action":["secretsmanager:GetSecretValue"],"Resource":["arn:aws:secretsmanager:${AWS_REGION}:${ACCOUNT_ID}:secret:${APP_NAME}-secrets*"]},
            {"Effect":"Allow","Action":["logs:CreateLogStream","logs:PutLogEvents","logs:CreateLogGroup"],"Resource":"arn:aws:logs:${AWS_REGION}:${ACCOUNT_ID}:*"}
          ]}
          POLICY
          aws iam put-role-policy --role-name "$EXEC_ROLE" --policy-name "${APP_NAME}-secrets-and-logs" \
            --policy-document file:///tmp/exec-policy.json 2>/dev/null || true

          # Task role
          TASK_ROLE="${APP_NAME}-ecs-task-role"
          if aws iam get-role --role-name "$TASK_ROLE" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Role exists: $TASK_ROLE"
          else
            aws iam create-role --role-name "$TASK_ROLE" --assume-role-policy-document "$TRUST_POLICY" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created role: $TASK_ROLE"
          fi

          # Task role inline policies (idempotent put)
          cat > /tmp/task-policy.json <<POLICY
          {"Version":"2012-10-17","Statement":[
            {"Effect":"Allow","Action":["dynamodb:GetItem","dynamodb:PutItem","dynamodb:UpdateItem","dynamodb:DeleteItem","dynamodb:Query","dynamodb:Scan","dynamodb:DescribeTable"],"Resource":["arn:aws:dynamodb:${AWS_REGION}:${ACCOUNT_ID}:table/${PROJECT_NAME}-${ENVIRONMENT}","arn:aws:dynamodb:${AWS_REGION}:${ACCOUNT_ID}:table/${PROJECT_NAME}-${ENVIRONMENT}/index/*"]},
            {"Sid":"CloudWatchMetrics","Effect":"Allow","Action":["cloudwatch:PutMetricData"],"Resource":"*","Condition":{"StringEquals":{"cloudwatch:namespace":"${PROJECT_NAME}/${ENVIRONMENT}"}}}
          ]}
          POLICY
          aws iam put-role-policy --role-name "$TASK_ROLE" --policy-name "${APP_NAME}-dynamodb-access" \
            --policy-document file:///tmp/task-policy.json 2>/dev/null || true

          # CodeDeploy service role (for Blue/Green ECS deployments)
          CODEDEPLOY_ROLE="${APP_NAME}-codedeploy-role"
          CODEDEPLOY_TRUST='{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"codedeploy.amazonaws.com"},"Action":"sts:AssumeRole"}]}'
          if aws iam get-role --role-name "$CODEDEPLOY_ROLE" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Role exists: $CODEDEPLOY_ROLE"
          else
            aws iam create-role --role-name "$CODEDEPLOY_ROLE" --assume-role-policy-document "$CODEDEPLOY_TRUST" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" --no-cli-pager >/dev/null
            aws iam attach-role-policy --role-name "$CODEDEPLOY_ROLE" \
              --policy-arn "arn:aws:iam::aws:policy/AWSCodeDeployRoleForECS"
            echo "  ‚úÖ Created role: $CODEDEPLOY_ROLE"
          fi

      # ‚îÄ‚îÄ 5. DynamoDB Table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create DynamoDB table
        run: |
          echo "üóÑÔ∏è  Ensuring DynamoDB table exists..."
          TABLE_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          if aws dynamodb describe-table --table-name "$TABLE_NAME" --region "$AWS_REGION" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Table exists: $TABLE_NAME"
          else
            aws dynamodb create-table --table-name "$TABLE_NAME" \
              --attribute-definitions \
                AttributeName=PK,AttributeType=S \
                AttributeName=SK,AttributeType=S \
                AttributeName=GSI1PK,AttributeType=S \
                AttributeName=GSI1SK,AttributeType=S \
              --key-schema AttributeName=PK,KeyType=HASH AttributeName=SK,KeyType=RANGE \
              --billing-mode PAY_PER_REQUEST \
              --global-secondary-indexes '[{"IndexName":"GSI1","KeySchema":[{"AttributeName":"GSI1PK","KeyType":"HASH"},{"AttributeName":"GSI1SK","KeyType":"RANGE"}],"Projection":{"ProjectionType":"ALL"}}]' \
              --tags Key=Environment,Value="$ENVIRONMENT" Key=Application,Value=ShoreExplorer Key=ManagedBy,Value=GitHubActions \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚è≥ Waiting for table to become active..."
            aws dynamodb wait table-exists --table-name "$TABLE_NAME" --region "$AWS_REGION"
            echo "  ‚úÖ Created table: $TABLE_NAME"
          fi

      # ‚îÄ‚îÄ 6. ECS Cluster & Log Groups ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ECS cluster and log groups
        run: |
          echo "üöÄ Ensuring ECS cluster and log groups exist..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          CLUSTER="${APP_NAME}-cluster"

          # Log groups
          for LG in "/ecs/${APP_NAME}-backend" "/ecs/${APP_NAME}-frontend"; do
            if aws logs describe-log-groups --log-group-name-prefix "$LG" --region "$AWS_REGION" \
              --query "logGroups[?logGroupName=='$LG']" --output text | grep -q "$LG"; then
              echo "  ‚è≠Ô∏è  Log group exists: $LG"
            else
              aws logs create-log-group --log-group-name "$LG" --region "$AWS_REGION" \
                --tags Project="$PROJECT_NAME",Environment="$ENVIRONMENT"
              echo "  ‚úÖ Created log group: $LG"
            fi
            aws logs put-retention-policy --log-group-name "$LG" --retention-in-days 14 --region "$AWS_REGION" 2>/dev/null || true
          done

          # Cluster
          CLUSTER_STATUS=$(aws ecs describe-clusters --clusters "$CLUSTER" --region "$AWS_REGION" \
            --query "clusters[0].status" --output text 2>/dev/null || echo "MISSING")
          if [[ "$CLUSTER_STATUS" == "ACTIVE" ]]; then
            echo "  ‚è≠Ô∏è  Cluster exists: $CLUSTER"
          else
            aws ecs create-cluster --cluster-name "$CLUSTER" \
              --capacity-providers FARGATE \
              --default-capacity-provider-strategy capacityProvider=FARGATE,weight=1 \
              --settings '[{"name":"containerInsights","value":"disabled"}]' \
              --tags key=Project,value="$PROJECT_NAME" key=Environment,value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created cluster: $CLUSTER"
          fi

      # ‚îÄ‚îÄ 7. ALB & Target Groups ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ALB and target groups
        id: alb
        run: |
          echo "‚öñÔ∏è  Ensuring ALB and target groups exist..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          ALB_NAME="${APP_NAME}-alb"
          VPC_ID="${{ steps.networking.outputs.vpc_id }}"
          PUB1="${{ steps.networking.outputs.pub_subnet_1 }}"
          PUB2="${{ steps.networking.outputs.pub_subnet_2 }}"
          ALB_SG="${{ steps.networking.outputs.alb_sg_id }}"

          # ALB
          ALB_ARN=$(aws elbv2 describe-load-balancers --names "$ALB_NAME" \
            --query "LoadBalancers[0].LoadBalancerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$ALB_ARN" == "None" || -z "$ALB_ARN" ]]; then
            ALB_ARN=$(aws elbv2 create-load-balancer --name "$ALB_NAME" \
              --subnets "$PUB1" "$PUB2" --security-groups "$ALB_SG" \
              --scheme internet-facing --type application --ip-address-type ipv4 \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "LoadBalancers[0].LoadBalancerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created ALB: $ALB_NAME"
          else
            echo "  ‚è≠Ô∏è  ALB exists: $ALB_NAME"
          fi

          ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns "$ALB_ARN" \
            --query "LoadBalancers[0].DNSName" --output text --region "$AWS_REGION")

          # Target Groups
          create_tg() {
            local TG_NAME="$1" PORT="$2" HEALTH="$3"
            local TG_ARN
            TG_ARN=$(aws elbv2 describe-target-groups --names "$TG_NAME" \
              --query "TargetGroups[0].TargetGroupArn" --output text \
              --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$TG_ARN" == "None" || -z "$TG_ARN" ]]; then
              TG_ARN=$(aws elbv2 create-target-group --name "$TG_NAME" \
                --protocol HTTP --port "$PORT" --vpc-id "$VPC_ID" --target-type ip \
                --health-check-protocol HTTP --health-check-path "$HEALTH" \
                --health-check-interval-seconds 30 --health-check-timeout-seconds 10 \
                --healthy-threshold-count 2 --unhealthy-threshold-count 3 --matcher HttpCode=200 \
                --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
                --query "TargetGroups[0].TargetGroupArn" --output text --region "$AWS_REGION")
              echo "  ‚úÖ Created TG: $TG_NAME" >&2
            else
              echo "  ‚è≠Ô∏è  TG exists: $TG_NAME" >&2
            fi
            echo "$TG_ARN"
          }

          BACKEND_TG_ARN=$(create_tg "${APP_NAME}-backend-tg" 8001 "/api/health")
          FRONTEND_TG_ARN=$(create_tg "${APP_NAME}-frontend-tg" 8080 "/")

          # Green target groups for CodeDeploy Blue/Green deployments
          BACKEND_GREEN_TG_ARN=$(create_tg "${APP_NAME}-be-green-tg" 8001 "/api/health")
          FRONTEND_GREEN_TG_ARN=$(create_tg "${APP_NAME}-fe-green-tg" 8080 "/")

          # HTTP Listener (port 80) ‚Äî will be converted to redirect later if HTTPS is set up
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn "$ALB_ARN" \
            --query "Listeners[?Port==\`80\`].ListenerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$LISTENER_ARN" || "$LISTENER_ARN" == "None" ]]; then
            LISTENER_ARN=$(aws elbv2 create-listener --load-balancer-arn "$ALB_ARN" \
              --protocol HTTP --port 80 \
              --default-actions Type=forward,TargetGroupArn="$FRONTEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "Listeners[0].ListenerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created HTTP listener"
          else
            echo "  ‚è≠Ô∏è  HTTP listener exists"
          fi

          # Listener rule: /api/* ‚Üí backend
          EXISTING_RULES=$(aws elbv2 describe-rules --listener-arn "$LISTENER_ARN" \
            --query "Rules[?Conditions[?Field=='path-pattern' && Values[0]=='/api/*']].RuleArn" \
            --output text --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$EXISTING_RULES" || "$EXISTING_RULES" == "None" ]]; then
            aws elbv2 create-rule --listener-arn "$LISTENER_ARN" --priority 10 \
              --conditions Field=path-pattern,Values='/api/*' \
              --actions Type=forward,TargetGroupArn="$BACKEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created /api/* listener rule"
          else
            echo "  ‚è≠Ô∏è  /api/* rule exists"
          fi

          echo "alb_arn=${ALB_ARN}" >> "$GITHUB_OUTPUT"
          echo "alb_dns=${ALB_DNS}" >> "$GITHUB_OUTPUT"
          echo "backend_tg_arn=${BACKEND_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "frontend_tg_arn=${FRONTEND_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "backend_green_tg_arn=${BACKEND_GREEN_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "frontend_green_tg_arn=${FRONTEND_GREEN_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "listener_arn=${LISTENER_ARN}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 8. HTTPS Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup HTTPS
        id: https
        env:
          TEST_DOMAIN: ${{ secrets.TEST_DOMAIN || '' }}
        run: |
          echo "üîí Setting up HTTPS..."
          ALB_ARN="${{ steps.alb.outputs.alb_arn }}"
          FRONTEND_TG_ARN="${{ steps.alb.outputs.frontend_tg_arn }}"
          BACKEND_TG_ARN="${{ steps.alb.outputs.backend_tg_arn }}"
          LISTENER_ARN="${{ steps.alb.outputs.listener_arn }}"

          if [[ -z "$TEST_DOMAIN" ]]; then
            echo "  ‚è≠Ô∏è  TEST_DOMAIN not set ‚Äî skipping HTTPS"
            echo "backend_url=http://${{ steps.alb.outputs.alb_dns }}" >> "$GITHUB_OUTPUT"
            echo "prod_listener_arn=${LISTENER_ARN}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          FULL_DOMAIN="test.${TEST_DOMAIN}"

          # Find existing wildcard certificate
          CERT_ARN=$(aws acm list-certificates --region "$AWS_REGION" \
            --query "CertificateSummaryList[?DomainName=='*.${TEST_DOMAIN}' && Status=='ISSUED'].CertificateArn" \
            --output text 2>/dev/null || echo "")

          if [[ -z "$CERT_ARN" || "$CERT_ARN" == "None" ]]; then
            echo "  ‚ö†Ô∏è  No issued wildcard certificate found for *.${TEST_DOMAIN}"
            echo "  Using ALB DNS directly"
            echo "backend_url=http://${{ steps.alb.outputs.alb_dns }}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "  ‚úÖ Found certificate: $CERT_ARN"

          # HTTPS listener (port 443)
          HTTPS_LISTENER=$(aws elbv2 describe-listeners --load-balancer-arn "$ALB_ARN" \
            --query "Listeners[?Port==\`443\`].ListenerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$HTTPS_LISTENER" || "$HTTPS_LISTENER" == "None" ]]; then
            HTTPS_LISTENER=$(aws elbv2 create-listener --load-balancer-arn "$ALB_ARN" \
              --protocol HTTPS --port 443 --certificates CertificateArn="$CERT_ARN" \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06 \
              --default-actions Type=forward,TargetGroupArn="$FRONTEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "Listeners[0].ListenerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created HTTPS listener"

            # Add /api/* rule to HTTPS listener
            aws elbv2 create-rule --listener-arn "$HTTPS_LISTENER" --priority 10 \
              --conditions Field=path-pattern,Values='/api/*' \
              --actions Type=forward,TargetGroupArn="$BACKEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created HTTPS /api/* rule"
          else
            echo "  ‚è≠Ô∏è  HTTPS listener exists"
            # Ensure correct certificate
            aws elbv2 modify-listener --listener-arn "$HTTPS_LISTENER" \
              --certificates CertificateArn="$CERT_ARN" --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
          fi

          # HTTP ‚Üí HTTPS redirect
          CURRENT_ACTION=$(aws elbv2 describe-listeners --listener-arns "$LISTENER_ARN" \
            --region "$AWS_REGION" --query 'Listeners[0].DefaultActions[0].Type' --output text 2>/dev/null || echo "")

          if [[ "$CURRENT_ACTION" != "redirect" ]]; then
            aws elbv2 modify-listener --listener-arn "$LISTENER_ARN" \
              --default-actions 'Type=redirect,RedirectConfig={Protocol=HTTPS,Port=443,StatusCode=HTTP_301}' \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ HTTP ‚Üí HTTPS redirect configured"
          else
            echo "  ‚è≠Ô∏è  HTTP redirect already configured"
          fi

          echo "backend_url=https://${FULL_DOMAIN}" >> "$GITHUB_OUTPUT"
          echo "prod_listener_arn=${HTTPS_LISTENER}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 9. DNS Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup DNS
        env:
          TEST_DOMAIN: ${{ secrets.TEST_DOMAIN || '' }}
        run: |
          echo "üåê Setting up DNS..."

          if [[ -z "$TEST_DOMAIN" ]]; then
            echo "  ‚è≠Ô∏è  TEST_DOMAIN not set ‚Äî skipping DNS"
            exit 0
          fi

          FULL_DOMAIN="test.${TEST_DOMAIN}"
          ALB_DNS="${{ steps.alb.outputs.alb_dns }}"
          ALB_NAME="${PROJECT_NAME}-${ENVIRONMENT}-alb"

          # Find hosted zone
          ZONE_ID=$(aws route53 list-hosted-zones-by-name \
            --query "HostedZones[?Name=='${TEST_DOMAIN}.'].Id" \
            --output text 2>/dev/null | cut -d'/' -f3 || echo "")

          if [[ -z "$ZONE_ID" || "$ZONE_ID" == "None" ]]; then
            echo "  ‚ö†Ô∏è  No hosted zone found for ${TEST_DOMAIN} ‚Äî skipping DNS"
            exit 0
          fi

          # Get ALB hosted zone ID
          ALB_ZONE_ID=$(aws elbv2 describe-load-balancers --names "$ALB_NAME" \
            --region "$AWS_REGION" --query "LoadBalancers[0].CanonicalHostedZoneId" --output text 2>/dev/null || echo "")

          if [[ -z "$ALB_ZONE_ID" || "$ALB_ZONE_ID" == "None" ]]; then
            echo "  ‚ö†Ô∏è  Could not get ALB zone ID ‚Äî skipping DNS"
            exit 0
          fi

          # Upsert DNS record
          CHANGE_BATCH=$(cat <<EOF
          {
            "Changes": [{
              "Action": "UPSERT",
              "ResourceRecordSet": {
                "Name": "${FULL_DOMAIN}",
                "Type": "A",
                "AliasTarget": {
                  "HostedZoneId": "${ALB_ZONE_ID}",
                  "DNSName": "${ALB_DNS}",
                  "EvaluateTargetHealth": false
                }
              }
            }]
          }
          EOF
          )

          aws route53 change-resource-record-sets --hosted-zone-id "$ZONE_ID" \
            --change-batch "$CHANGE_BATCH" --no-cli-pager >/dev/null
          echo "  ‚úÖ DNS record set: ${FULL_DOMAIN} ‚Üí ${ALB_DNS}"

      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      #  BUILD & DEPLOY APPLICATION
      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

      # ‚îÄ‚îÄ 10. Build & Push Images ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push backend image
        run: |
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          docker build \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:${IMAGE_TAG}" \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:${ENVIRONMENT}-latest" \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:latest" \
            -f backend/Dockerfile backend/
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:${IMAGE_TAG}"
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:${ENVIRONMENT}-latest"
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:latest"

      - name: Build and push frontend image
        run: |
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          BACKEND_URL="${{ steps.https.outputs.backend_url }}"

          # Fallback if HTTPS step didn't set backend_url
          if [[ -z "$BACKEND_URL" ]]; then
            BACKEND_URL="http://${{ steps.alb.outputs.alb_dns }}"
          fi

          docker build \
            --build-arg REACT_APP_BACKEND_URL="${BACKEND_URL}" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:${IMAGE_TAG}" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:${ENVIRONMENT}-latest" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:latest" \
            -f frontend/Dockerfile frontend/
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:${IMAGE_TAG}"
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:${ENVIRONMENT}-latest"
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:latest"

      # ‚îÄ‚îÄ 11. Register Task Definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Register backend task definition
        run: |
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          SECRET_ARN="${{ steps.secrets.outputs.secret_arn }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          EXEC_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-execution-role" \
            --query 'Role.Arn' --output text)
          TASK_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-role" \
            --query 'Role.Arn' --output text)

          aws ecs register-task-definition \
            --family "${APP_NAME}-backend-task" \
            --network-mode awsvpc --requires-compatibilities FARGATE \
            --cpu 256 --memory 512 \
            --execution-role-arn "$EXEC_ROLE_ARN" --task-role-arn "$TASK_ROLE_ARN" \
            --container-definitions "[{
              \"name\": \"backend\",
              \"image\": \"${ECR_BASE}/${BACKEND_ECR_REPO}:${ENVIRONMENT}-latest\",
              \"essential\": true,
              \"portMappings\": [{\"containerPort\": 8001, \"protocol\": \"tcp\"}],
              \"secrets\": [{\"name\": \"GROQ_API_KEY\", \"valueFrom\": \"${SECRET_ARN}:GROQ_API_KEY::\"}],
              \"environment\": [
                {\"name\": \"DYNAMODB_TABLE_NAME\", \"value\": \"${PROJECT_NAME}-${ENVIRONMENT}\"},
                {\"name\": \"AWS_DEFAULT_REGION\", \"value\": \"${AWS_REGION}\"},
                {\"name\": \"ENVIRONMENT\", \"value\": \"${ENVIRONMENT}\"},
                {\"name\": \"ENABLE_CLOUDWATCH_METRICS\", \"value\": \"true\"}
              ],
              \"logConfiguration\": {
                \"logDriver\": \"awslogs\",
                \"options\": {
                  \"awslogs-group\": \"/ecs/${APP_NAME}-backend\",
                  \"awslogs-region\": \"${AWS_REGION}\",
                  \"awslogs-stream-prefix\": \"ecs\"
                }
              },
              \"healthCheck\": {
                \"command\": [\"CMD-SHELL\", \"python -c \\\"import urllib.request; exit(0 if urllib.request.urlopen('http://localhost:8001/api/health').status == 200 else 1)\\\"\"],
                \"interval\": 30, \"timeout\": 10, \"retries\": 3, \"startPeriod\": 60
              }
            }]" \
            --tags "key=Project,value=$PROJECT_NAME" "key=Environment,value=$ENVIRONMENT" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null
          echo "‚úÖ Registered backend task definition"

      - name: Register frontend task definition
        run: |
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          EXEC_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-execution-role" \
            --query 'Role.Arn' --output text)
          TASK_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-role" \
            --query 'Role.Arn' --output text)

          aws ecs register-task-definition \
            --family "${APP_NAME}-frontend-task" \
            --network-mode awsvpc --requires-compatibilities FARGATE \
            --cpu 256 --memory 512 \
            --execution-role-arn "$EXEC_ROLE_ARN" --task-role-arn "$TASK_ROLE_ARN" \
            --container-definitions "[{
              \"name\": \"frontend\",
              \"image\": \"${ECR_BASE}/${FRONTEND_ECR_REPO}:${ENVIRONMENT}-latest\",
              \"essential\": true,
              \"portMappings\": [{\"containerPort\": 8080, \"protocol\": \"tcp\"}],
              \"logConfiguration\": {
                \"logDriver\": \"awslogs\",
                \"options\": {
                  \"awslogs-group\": \"/ecs/${APP_NAME}-frontend\",
                  \"awslogs-region\": \"${AWS_REGION}\",
                  \"awslogs-stream-prefix\": \"ecs\"
                }
              },
              \"healthCheck\": {
                \"command\": [\"CMD-SHELL\", \"wget --quiet --tries=1 --spider http://localhost:8080/ || exit 1\"],
                \"interval\": 30, \"timeout\": 5, \"retries\": 3, \"startPeriod\": 30
              }
            }]" \
            --tags "key=Project,value=$PROJECT_NAME" "key=Environment,value=$ENVIRONMENT" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null
          echo "‚úÖ Registered frontend task definition"

      # ‚îÄ‚îÄ 12. Create/Update ECS Services (Blue/Green via CodeDeploy) ‚îÄ‚îÄ
      - name: Create or update ECS services
        run: |
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          CLUSTER="${APP_NAME}-cluster"
          ECS_SG="${{ steps.networking.outputs.ecs_sg_id }}"
          PUB1="${{ steps.networking.outputs.pub_subnet_1 }}"
          PUB2="${{ steps.networking.outputs.pub_subnet_2 }}"
          BACKEND_TG="${{ steps.alb.outputs.backend_tg_arn }}"
          FRONTEND_TG="${{ steps.alb.outputs.frontend_tg_arn }}"

          # Helper: create or migrate an ECS service to CODE_DEPLOY controller
          create_or_migrate_service() {
            local SVC_NAME="$1" TASK_FAMILY="$2" TG_ARN="$3"
            local CONTAINER_NAME="$4" CONTAINER_PORT="$5" GRACE="$6"

            EXISTING=$(aws ecs describe-services --cluster "$CLUSTER" --services "$SVC_NAME" \
              --query "services[?status=='ACTIVE'].serviceName" --output text \
              --region "$AWS_REGION" 2>/dev/null || echo "")

            if [[ -n "$EXISTING" && "$EXISTING" != "None" ]]; then
              # Check if service already uses CODE_DEPLOY controller
              CONTROLLER=$(aws ecs describe-services --cluster "$CLUSTER" --services "$SVC_NAME" \
                --query "services[0].deploymentController.type" --output text \
                --region "$AWS_REGION" 2>/dev/null || echo "ECS")

              if [[ "$CONTROLLER" == "CODE_DEPLOY" ]]; then
                echo "  ‚è≠Ô∏è  ${SVC_NAME} already uses CODE_DEPLOY controller"
                return 0
              fi

              # Migrate from ECS rolling to CODE_DEPLOY (requires service recreation)
              echo "  üîÑ Migrating ${SVC_NAME} to CODE_DEPLOY controller..."
              aws ecs update-service --cluster "$CLUSTER" --service "$SVC_NAME" \
                --desired-count 0 --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
              aws ecs delete-service --cluster "$CLUSTER" --service "$SVC_NAME" \
                --force --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
              # Brief wait for service deletion to propagate
              sleep 15
            fi

            aws ecs create-service --cluster "$CLUSTER" --service-name "$SVC_NAME" \
              --task-definition "$TASK_FAMILY" --desired-count 1 --launch-type FARGATE \
              --deployment-controller type=CODE_DEPLOY \
              --network-configuration "awsvpcConfiguration={subnets=[$PUB1,$PUB2],securityGroups=[$ECS_SG],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=${TG_ARN},containerName=${CONTAINER_NAME},containerPort=${CONTAINER_PORT}" \
              --health-check-grace-period-seconds "$GRACE" \
              --tags key=Project,value="$PROJECT_NAME" key=Environment,value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created ${SVC_NAME} with CODE_DEPLOY controller"
          }

          create_or_migrate_service "${APP_NAME}-backend"  "${APP_NAME}-backend-task"  "$BACKEND_TG"  "backend"  8001 120
          create_or_migrate_service "${APP_NAME}-frontend" "${APP_NAME}-frontend-task" "$FRONTEND_TG" "frontend" 8080 60

      # ‚îÄ‚îÄ 12b. CodeDeploy Application & Deployment Groups ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create CodeDeploy application and deployment groups
        run: |
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          CODEDEPLOY_APP="${APP_NAME}-codedeploy"
          CODEDEPLOY_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-codedeploy-role" \
            --query 'Role.Arn' --output text --region "$AWS_REGION")

          # Determine production traffic listener (HTTPS if available, else HTTP)
          PROD_LISTENER="${{ steps.https.outputs.prod_listener_arn }}"
          if [[ -z "$PROD_LISTENER" || "$PROD_LISTENER" == "None" ]]; then
            PROD_LISTENER="${{ steps.alb.outputs.listener_arn }}"
          fi

          # Create CodeDeploy application (ECS compute platform)
          if aws deploy get-application --application-name "$CODEDEPLOY_APP" \
               --region "$AWS_REGION" &>/dev/null; then
            echo "  ‚è≠Ô∏è  CodeDeploy application exists: $CODEDEPLOY_APP"
          else
            aws deploy create-application --application-name "$CODEDEPLOY_APP" \
              --compute-platform ECS --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created CodeDeploy application: $CODEDEPLOY_APP"
          fi

          # Helper: create or update a CodeDeploy deployment group
          create_or_update_dg() {
            local DG_NAME="$1" SVC_NAME="$2" BLUE_TG="$3" GREEN_TG="$4"

            LOAD_BALANCER_INFO=$(cat <<EOF
          {
            "targetGroupPairInfoList": [{
              "targetGroups": [
                {"name": "${BLUE_TG}"},
                {"name": "${GREEN_TG}"}
              ],
              "prodTrafficRoute": {
                "listenerArns": ["${PROD_LISTENER}"]
              }
            }]
          }
          EOF
          )

            BG_CONFIG=$(cat <<EOF
          {
            "terminateBlueInstancesOnDeploymentSuccess": {
              "action": "TERMINATE",
              "terminationWaitTimeInMinutes": 5
            },
            "deploymentReadyOption": {
              "actionOnTimeout": "CONTINUE_DEPLOYMENT",
              "waitTimeInMinutes": 0
            }
          }
          EOF
          )

            if aws deploy get-deployment-group --application-name "$CODEDEPLOY_APP" \
                 --deployment-group-name "$DG_NAME" --region "$AWS_REGION" &>/dev/null; then
              aws deploy update-deployment-group \
                --application-name "$CODEDEPLOY_APP" \
                --current-deployment-group-name "$DG_NAME" \
                --service-role-arn "$CODEDEPLOY_ROLE_ARN" \
                --ecs-services "clusterName=${APP_NAME}-cluster,serviceName=${SVC_NAME}" \
                --load-balancer-info "$LOAD_BALANCER_INFO" \
                --blue-green-deployment-configuration "$BG_CONFIG" \
                --deployment-config-name CodeDeployDefault.ECSAllAtOnce \
                --auto-rollback-configuration "enabled=true,events=DEPLOYMENT_FAILURE" \
                --region "$AWS_REGION" --no-cli-pager >/dev/null
              echo "  ‚è≠Ô∏è  Updated deployment group: $DG_NAME"
            else
              aws deploy create-deployment-group \
                --application-name "$CODEDEPLOY_APP" \
                --deployment-group-name "$DG_NAME" \
                --service-role-arn "$CODEDEPLOY_ROLE_ARN" \
                --ecs-services "clusterName=${APP_NAME}-cluster,serviceName=${SVC_NAME}" \
                --load-balancer-info "$LOAD_BALANCER_INFO" \
                --blue-green-deployment-configuration "$BG_CONFIG" \
                --deployment-config-name CodeDeployDefault.ECSAllAtOnce \
                --auto-rollback-configuration "enabled=true,events=DEPLOYMENT_FAILURE" \
                --region "$AWS_REGION" --no-cli-pager >/dev/null
              echo "  ‚úÖ Created deployment group: $DG_NAME"
            fi
          }

          create_or_update_dg "${APP_NAME}-backend-dg"  "${APP_NAME}-backend"  "${APP_NAME}-backend-tg"  "${APP_NAME}-be-green-tg"
          create_or_update_dg "${APP_NAME}-frontend-dg" "${APP_NAME}-frontend" "${APP_NAME}-frontend-tg" "${APP_NAME}-fe-green-tg"

      # ‚îÄ‚îÄ 13. Async Deployment Callback (LEAN WAIT) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Provision async deployment callback infrastructure
        env:
          GH_TOKEN: ${{ secrets.GH_CALLBACK_TOKEN }}
        run: |
          # Only provision if callback token is available
          if [[ -z "$GH_TOKEN" ]]; then
            echo "‚è≠Ô∏è  GH_CALLBACK_TOKEN is not set. Skipping callback infrastructure setup."
            echo "Deployment will still occur, but without the automated async callback job."
            exit 0
          fi

          echo "üöÄ Provisioning EventBridge-to-GitHub callback infrastructure..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          
          # best-effort self-grant of EventBridge/IAM permissions (setup runs with
          # the same credentials that will be used for deployments)
          if aws iam get-user &>/dev/null 2>&1; then
            USERNAME=$(aws iam get-user --query 'User.UserName' --output text)
            # Full permission block required for EventBridge to manage its own connections (incl. Secrets Manager)
            CALLBACK_POLICY='{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Action":["events:CreateConnection","events:DescribeConnection","events:UpdateConnection","events:CreateApiDestination","events:DescribeApiDestination","events:UpdateApiDestination","events:PutRule","events:PutTargets","iam:GetRole","iam:CreateRole","iam:PutRolePolicy","iam:PutUserPolicy","iam:PassRole","iam:CreateServiceLinkedRole","secretsmanager:CreateSecret","secretsmanager:TagResource","secretsmanager:GetSecretValue","secretsmanager:PutSecretValue","secretsmanager:DescribeSecret","secretsmanager:UpdateSecret","secretsmanager:DeleteSecret"],"Resource":"*"}]}'
            aws iam put-user-policy --user-name "$USERNAME" --policy-name "ShoreExplorerCallbackHelper" --policy-document "$CALLBACK_POLICY" >/dev/null 2>&1 || true
            # Wait for IAM inline-policy propagation before proceeding
            sleep 15
          fi

          # helper for permission errors
          fail() {
            echo "‚ùå $1"
            echo "   Error Details: ${2:-No additional info}"
            echo "   Deployment will continue, but the async callback won't be configured."
            # We exit 0 because if callback infrastructure fails, we don't want to break the whole deployment.
            exit 0
          }

          # 1. Connection (Auth for GitHub)
          CONN_ARN=$(aws events describe-connection --name "${APP_NAME}-gh-conn" \
            --query 'ConnectionArn' --output text --region "$AWS_REGION" 2>/dev/null || echo "")
          
          if [[ -z "$CONN_ARN" || "$CONN_ARN" == "None" ]]; then
            if ! CONN_OUTPUT=$(aws events create-connection --name "${APP_NAME}-gh-conn" \
              --authorization-type API_KEY \
              --auth-parameters "{\"ApiKeyAuthParameters\": {\"ApiKeyName\": \"Authorization\", \"ApiKeyValue\": \"Bearer ${GH_TOKEN}\"}}" \
              --region "$AWS_REGION" 2>&1); then
              fail "Unable to create EventBridge Connection. Ensure deployment role has events:CreateConnection and related Secrets Manager actions." "$CONN_OUTPUT"
            fi
            CONN_ARN=$(echo "$CONN_OUTPUT" | grep -o 'arn:aws:events:[^"]*')
            echo "  ‚úÖ Created EventBridge Connection"
          else
            echo "  ‚è≠Ô∏è  Connection exists"
          fi

          # 2. API Destination (GitHub Repos Dispatch)
          DEST_ARN=$(aws events describe-api-destination --name "${APP_NAME}-gh-dispatch" \
            --query 'ApiDestinationArn' --output text --region "$AWS_REGION" 2>/dev/null || echo "")
          
          if [[ -z "$DEST_ARN" || "$DEST_ARN" == "None" ]]; then
            DEST_URL="https://api.github.com/repos/${{ github.repository }}/dispatches"
            if ! DEST_OUTPUT=$(aws events create-api-destination --name "${APP_NAME}-gh-dispatch" \
              --connection-arn "$CONN_ARN" \
              --invocation-endpoint "$DEST_URL" \
              --http-method POST \
              --region "$AWS_REGION" 2>&1); then
              fail "Unable to create API Destination. Ensure deployment role has events:CreateApiDestination." "$DEST_OUTPUT"
            fi
            DEST_ARN=$(echo "$DEST_OUTPUT" | grep -o 'arn:aws:events:[^"]*')
            echo "  ‚úÖ Created API Destination"
          else
            echo "  ‚è≠Ô∏è  API Destination exists"
          fi

          # 3. IAM Role for EventBridge to call API Destination
          ROLE_NAME="${APP_NAME}-eventbridge-callback-role"
          if ! aws iam get-role --role-name "$ROLE_NAME" &>/dev/null; then
            TRUST_POLICY='{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"events.amazonaws.com"},"Action":"sts:AssumeRole"}]}'
            if ! aws iam create-role --role-name "$ROLE_NAME" --assume-role-policy-document "$TRUST_POLICY" >/dev/null 2>&1; then
              fail "Unable to create IAM role. Ensure deployment role has iam:CreateRole."
            fi
            
            POLICY_DOC="{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"events:InvokeApiDestination\",\"Resource\":\"$DEST_ARN\"}]}"
            if ! aws iam put-role-policy --role-name "$ROLE_NAME" --policy-name "InvokeAPIDestination" --policy-document "$POLICY_DOC" >/dev/null 2>&1; then
              fail "Unable to attach policy to callback IAM role. Ensure deployment role has iam:PutRolePolicy."
            fi
            echo "  ‚úÖ Created IAM Role for EventBridge callback"
          fi
          ROLE_ARN=$(aws iam get-role --role-name "$ROLE_NAME" --query 'Role.Arn' --output text)

          # 4. Rule (Listen for CodeDeploy SUCCESS)
          CODEDEPLOY_APP="${APP_NAME}-codedeploy"
          aws events put-rule --name "${APP_NAME}-codedeploy-success-rule" \
            --event-pattern "{\"source\":[\"aws.codedeploy\"],\"detail-type\":[\"CodeDeploy Deployment State-change Notification\"],\"detail\":{\"application\":[\"${CODEDEPLOY_APP}\"],\"state\":[\"SUCCESS\"]}}" \
            --state ENABLED --region "$AWS_REGION" --no-cli-pager >/dev/null
          
          aws events put-targets --rule "${APP_NAME}-codedeploy-success-rule" --region "$AWS_REGION" \
            --targets "[{\"Id\":\"GitHubSuccessDispatch\",\"Arn\":\"$DEST_ARN\",\"RoleArn\":\"$ROLE_ARN\",\"HttpParameters\":{\"QueryStringParameters\":{},\"HeaderParameters\":{\"User-Agent\":\"AWS-EventBridge\"}},\"InputTransformer\":{\"InputPathsMap\":{\"app\":\"$.detail.application\",\"dg\":\"$.detail.deploymentGroup\"},\"InputTemplate\":\"{\\\"event_type\\\": \\\"codedeploy_deploy_success\\\", \\\"client_payload\\\": {\\\"environment\\\": \\\"${ENVIRONMENT}\\\", \\\"application\\\": \\\"${CODEDEPLOY_APP}\\\", \\\"deployment_group\\\": \\\"<dg>\\\", \\\"status\\\": \\\"success\\\"}}\"}}]" \
            --no-cli-pager >/dev/null
          echo "  ‚úÖ Configured CodeDeploy Success Callback Route"

          # 5. Rule (Listen for CodeDeploy FAILURE / STOP)
          aws events put-rule --name "${APP_NAME}-codedeploy-failure-rule" \
            --event-pattern "{\"source\":[\"aws.codedeploy\"],\"detail-type\":[\"CodeDeploy Deployment State-change Notification\"],\"detail\":{\"application\":[\"${CODEDEPLOY_APP}\"],\"state\":[\"FAILURE\",\"STOP\"]}}" \
            --state ENABLED --region "$AWS_REGION" --no-cli-pager >/dev/null
          
          aws events put-targets --rule "${APP_NAME}-codedeploy-failure-rule" --region "$AWS_REGION" \
            --targets "[{\"Id\":\"GitHubFailureDispatch\",\"Arn\":\"$DEST_ARN\",\"RoleArn\":\"$ROLE_ARN\",\"HttpParameters\":{\"QueryStringParameters\":{},\"HeaderParameters\":{\"User-Agent\":\"AWS-EventBridge\"}},\"InputTransformer\":{\"InputPathsMap\":{\"app\":\"$.detail.application\",\"dg\":\"$.detail.deploymentGroup\"},\"InputTemplate\":\"{\\\"event_type\\\": \\\"codedeploy_deploy_failed\\\", \\\"client_payload\\\": {\\\"environment\\\": \\\"${ENVIRONMENT}\\\", \\\"application\\\": \\\"${CODEDEPLOY_APP}\\\", \\\"deployment_group\\\": \\\"<dg>\\\", \\\"status\\\": \\\"failed\\\"}}\"}}]" \
            --no-cli-pager >/dev/null
          echo "  ‚úÖ Configured CodeDeploy Failure Callback Route"

          # 6. Clean up old ECS-based callback rules (if they exist)
          aws events remove-targets --rule "${APP_NAME}-ecs-success-rule" --ids "GitHubSuccessDispatch" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
          aws events delete-rule --name "${APP_NAME}-ecs-success-rule" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
          aws events remove-targets --rule "${APP_NAME}-ecs-failure-rule" --ids "GitHubFailureDispatch" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
          aws events delete-rule --name "${APP_NAME}-ecs-failure-rule" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true

      # ‚îÄ‚îÄ 14. Monitoring ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup monitoring
        env:
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL || '' }}
        run: |
          chmod +x infra/aws/scripts/10-setup-monitoring.sh
          bash infra/aws/scripts/10-setup-monitoring.sh "${ENVIRONMENT}"
        continue-on-error: true

      # ‚îÄ‚îÄ Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Deployment summary
        if: always()
        run: |
          BACKEND_URL="${{ steps.https.outputs.backend_url }}"
          if [[ -z "$BACKEND_URL" ]]; then
            BACKEND_URL="http://${{ steps.alb.outputs.alb_dns }}"
          fi

          echo "## Test Environment Setup & Deploy Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "| Item | Value |" >> "$GITHUB_STEP_SUMMARY"
          echo "|------|-------|" >> "$GITHUB_STEP_SUMMARY"
          echo "| Environment | \`test\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Image Tag | \`${{ steps.vars.outputs.image_tag }}\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Commit | \`${{ github.sha }}\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| App URL | ${BACKEND_URL} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| API Health | ${BACKEND_URL}/api/health |" >> "$GITHUB_STEP_SUMMARY"
          DASHBOARD_URL="https://${AWS_REGION}.console.aws.amazon.com/cloudwatch/home?region=${AWS_REGION}#dashboards:name=${PROJECT_NAME}-${ENVIRONMENT}-dashboard"
          echo "| Dashboard | [CloudWatch](${DASHBOARD_URL}) |" >> "$GITHUB_STEP_SUMMARY"

  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  # Post-deployment cleanup and smoke tests
  # Runs ONCE after both services have deployed
  # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  cleanup-and-smoke:
    name: Deployment Cleanup & Smoke Test
    runs-on: ubuntu-latest
    needs: setup-and-deploy-test
    if: always()
    environment: test-post-deploy

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get deployment URL
        id: alb
        env:
          CUSTOM_DOMAIN: ${{ secrets.TEST_DOMAIN || '' }}
        run: |
          ALB_DNS=$(aws elbv2 describe-load-balancers \
            --names "${PROJECT_NAME}-${ENVIRONMENT}-alb" \
            --query "LoadBalancers[0].DNSName" \
            --output text --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -n "$CUSTOM_DOMAIN" ]]; then
            URL="https://test.${CUSTOM_DOMAIN}"
          elif [[ -n "$ALB_DNS" && "$ALB_DNS" != "None" ]]; then
            URL="https://${ALB_DNS}"
          else
            URL="http://localhost:8001"
          fi
          echo "url=${URL}" >> "$GITHUB_OUTPUT"

      # NOTE: No ECS polling needed ‚Äî the environment gate (test-post-deploy)
      # holds this job until the CodeDeploy callback approves it, meaning
      # services are already stable when this job starts running.

      - name: Run smoke tests
        if: needs.setup-and-deploy-test.result == 'success' && steps.alb.outputs.url != 'http://localhost:8001'
        run: |
          URL="${{ steps.alb.outputs.url }}"
          echo "Running smoke tests against ${URL}"
          sleep 15

          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${URL}/api/health" --max-time 30 || echo "000")
          if [[ "$HTTP_CODE" == "200" ]]; then
            echo "‚úÖ Health check passed (HTTP $HTTP_CODE)"
          else
            echo "‚ùå Health check failed (HTTP $HTTP_CODE)"
            exit 1
          fi

          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${URL}/" --max-time 30 || echo "000")
          if [[ "$HTTP_CODE" == "200" ]]; then
            echo "‚úÖ Frontend accessible (HTTP $HTTP_CODE)"
          else
            echo "‚ùå Frontend check failed (HTTP $HTTP_CODE)"
            exit 1
          fi

      - name: Smoke test & cleanup summary
        if: always()
        run: |
          DEPLOY_STATUS="${{ needs.setup-and-deploy-test.result }}"
          echo "## Deployment Cleanup & Smoke Test" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "| Item | Value |" >> "$GITHUB_STEP_SUMMARY"
          echo "|------|-------|" >> "$GITHUB_STEP_SUMMARY"
          echo "| Environment | \`${ENVIRONMENT}\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Setup & Deploy Result | \`${DEPLOY_STATUS}\` |" >> "$GITHUB_STEP_SUMMARY"
          if [[ "${{ steps.alb.outputs.url }}" != "" && "${{ steps.alb.outputs.url }}" != "http://localhost:8001" ]]; then
            echo "| App URL | ${{ steps.alb.outputs.url }} |" >> "$GITHUB_STEP_SUMMARY"
            echo "| API Health | ${{ steps.alb.outputs.url }}/api/health |" >> "$GITHUB_STEP_SUMMARY"
          fi
