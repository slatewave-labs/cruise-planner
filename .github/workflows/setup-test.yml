name: Setup & Deploy Test Environment

# Provisions all AWS infrastructure from scratch and deploys the application.
# Self-healing: skips resources that already exist.

on:
  workflow_dispatch: {}

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
  ENVIRONMENT: test
  PROJECT_NAME: shoreexplorer
  BACKEND_ECR_REPO: shoreexplorer-backend
  FRONTEND_ECR_REPO: shoreexplorer-frontend

jobs:
  setup-and-deploy-test:
    name: Setup & Deploy Test
    runs-on: ubuntu-latest
    environment: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set variables
        id: vars
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_BASE="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
          GIT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)
          IMAGE_TAG="${ENVIRONMENT}-${GIT_SHA}"

          echo "account_id=${ACCOUNT_ID}" >> "$GITHUB_OUTPUT"
          echo "ecr_base=${ECR_BASE}" >> "$GITHUB_OUTPUT"
          echo "image_tag=${IMAGE_TAG}" >> "$GITHUB_OUTPUT"

      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      #  INFRASTRUCTURE PROVISIONING
      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

      # ‚îÄ‚îÄ 1. ECR Repositories (shared) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ECR repositories
        run: |
          echo "üì¶ Ensuring ECR repositories exist..."
          for REPO in "$BACKEND_ECR_REPO" "$FRONTEND_ECR_REPO"; do
            if aws ecr describe-repositories --repository-names "$REPO" --region "$AWS_REGION" &>/dev/null; then
              echo "  ‚è≠Ô∏è  ECR repo exists: $REPO"
            else
              aws ecr create-repository --repository-name "$REPO" --region "$AWS_REGION" \
                --image-scanning-configuration scanOnPush=true --image-tag-mutability MUTABLE \
                --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value=shared \
                --no-cli-pager
              echo "  ‚úÖ Created ECR repo: $REPO"
            fi

            # Set lifecycle policy
            aws ecr put-lifecycle-policy --repository-name "$REPO" --region "$AWS_REGION" \
              --lifecycle-policy-text '{"rules":[{"rulePriority":1,"description":"Keep last 10","selection":{"tagStatus":"any","countType":"imageCountMoreThan","countNumber":10},"action":{"type":"expire"}}]}' \
              --no-cli-pager >/dev/null 2>&1 || true
          done

      # ‚îÄ‚îÄ 2. VPC & Networking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create networking
        id: networking
        run: |
          echo "üåê Provisioning networking..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          VPC_CIDR="10.0.0.0/16"
          AZ1="${AWS_REGION}a"
          AZ2="${AWS_REGION}b"

          # VPC
          VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=${APP_NAME}-vpc" \
            --query "Vpcs[0].VpcId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$VPC_ID" == "None" || -z "$VPC_ID" ]]; then
            VPC_ID=$(aws ec2 create-vpc --cidr-block "$VPC_CIDR" \
              --tag-specifications "ResourceType=vpc,Tags=[{Key=Name,Value=${APP_NAME}-vpc},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "Vpc.VpcId" --output text --region "$AWS_REGION")
            aws ec2 modify-vpc-attribute --vpc-id "$VPC_ID" --enable-dns-hostnames '{"Value":true}' --region "$AWS_REGION"
            aws ec2 modify-vpc-attribute --vpc-id "$VPC_ID" --enable-dns-support '{"Value":true}' --region "$AWS_REGION"
            echo "  ‚úÖ Created VPC: $VPC_ID"
          else
            echo "  ‚è≠Ô∏è  VPC exists: $VPC_ID"
          fi

          # Internet Gateway
          IGW_ID=$(aws ec2 describe-internet-gateways \
            --filters "Name=tag:Name,Values=${APP_NAME}-igw" \
            --query "InternetGateways[0].InternetGatewayId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$IGW_ID" == "None" || -z "$IGW_ID" ]]; then
            IGW_ID=$(aws ec2 create-internet-gateway \
              --tag-specifications "ResourceType=internet-gateway,Tags=[{Key=Name,Value=${APP_NAME}-igw},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "InternetGateway.InternetGatewayId" --output text --region "$AWS_REGION")
            aws ec2 attach-internet-gateway --internet-gateway-id "$IGW_ID" --vpc-id "$VPC_ID" --region "$AWS_REGION"
            echo "  ‚úÖ Created IGW: $IGW_ID"
          else
            echo "  ‚è≠Ô∏è  IGW exists: $IGW_ID"
          fi

          # Helper function for subnet creation
          create_subnet() {
            local NAME="$1" CIDR="$2" AZ="$3" MAP_PUBLIC="$4"
            local SID
            SID=$(aws ec2 describe-subnets \
              --filters "Name=tag:Name,Values=$NAME" "Name=vpc-id,Values=$VPC_ID" \
              --query "Subnets[0].SubnetId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$SID" == "None" || -z "$SID" ]]; then
              SID=$(aws ec2 create-subnet --vpc-id "$VPC_ID" --cidr-block "$CIDR" --availability-zone "$AZ" \
                --tag-specifications "ResourceType=subnet,Tags=[{Key=Name,Value=$NAME},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
                --query "Subnet.SubnetId" --output text --region "$AWS_REGION")
              if [[ "$MAP_PUBLIC" == "true" ]]; then
                aws ec2 modify-subnet-attribute --subnet-id "$SID" --map-public-ip-on-launch --region "$AWS_REGION"
              fi
              echo "  ‚úÖ Created subnet: $NAME ($SID)" >&2
            else
              echo "  ‚è≠Ô∏è  Subnet exists: $NAME ($SID)" >&2
            fi
            echo "$SID"
          }

          PUB1=$(create_subnet "${APP_NAME}-public-1" "10.0.1.0/24" "$AZ1" "true")
          PUB2=$(create_subnet "${APP_NAME}-public-2" "10.0.2.0/24" "$AZ2" "true")
          create_subnet "${APP_NAME}-private-1" "10.0.3.0/24" "$AZ1" "false" >/dev/null
          create_subnet "${APP_NAME}-private-2" "10.0.4.0/24" "$AZ2" "false" >/dev/null

          # Route Table
          RT_ID=$(aws ec2 describe-route-tables \
            --filters "Name=tag:Name,Values=${APP_NAME}-public-rt" "Name=vpc-id,Values=$VPC_ID" \
            --query "RouteTables[0].RouteTableId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$RT_ID" == "None" || -z "$RT_ID" ]]; then
            RT_ID=$(aws ec2 create-route-table --vpc-id "$VPC_ID" \
              --tag-specifications "ResourceType=route-table,Tags=[{Key=Name,Value=${APP_NAME}-public-rt},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
              --query "RouteTable.RouteTableId" --output text --region "$AWS_REGION")
            aws ec2 create-route --route-table-id "$RT_ID" --destination-cidr-block "0.0.0.0/0" --gateway-id "$IGW_ID" --region "$AWS_REGION" >/dev/null
            echo "  ‚úÖ Created route table: $RT_ID"
          else
            echo "  ‚è≠Ô∏è  Route table exists: $RT_ID"
          fi

          # Associate subnets
          for SID in "$PUB1" "$PUB2"; do
            ASSOC=$(aws ec2 describe-route-tables \
              --filters "Name=association.subnet-id,Values=$SID" "Name=route-table-id,Values=$RT_ID" \
              --query "RouteTables[0].RouteTableId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$ASSOC" == "None" || -z "$ASSOC" ]]; then
              aws ec2 associate-route-table --subnet-id "$SID" --route-table-id "$RT_ID" --region "$AWS_REGION" >/dev/null
            fi
          done

          # Security Groups
          create_sg() {
            local SG_NAME="$1" DESC="$2"
            local SGID
            SGID=$(aws ec2 describe-security-groups \
              --filters "Name=group-name,Values=$SG_NAME" "Name=vpc-id,Values=$VPC_ID" \
              --query "SecurityGroups[0].GroupId" --output text --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$SGID" == "None" || -z "$SGID" ]]; then
              SGID=$(aws ec2 create-security-group --group-name "$SG_NAME" --description "$DESC" --vpc-id "$VPC_ID" \
                --tag-specifications "ResourceType=security-group,Tags=[{Key=Name,Value=$SG_NAME},{Key=Project,Value=$PROJECT_NAME},{Key=Environment,Value=$ENVIRONMENT}]" \
                --query "GroupId" --output text --region "$AWS_REGION")
              echo "  ‚úÖ Created SG: $SG_NAME ($SGID)" >&2
            else
              echo "  ‚è≠Ô∏è  SG exists: $SG_NAME ($SGID)" >&2
            fi
            echo "$SGID"
          }

          ALB_SG_ID=$(create_sg "${APP_NAME}-alb-sg" "ALB security group")
          ECS_SG_ID=$(create_sg "${APP_NAME}-ecs-sg" "ECS tasks security group")

          # SG rules (idempotent)
          for PORT in 80 443; do
            aws ec2 authorize-security-group-ingress --group-id "$ALB_SG_ID" \
              --protocol tcp --port "$PORT" --cidr "0.0.0.0/0" --region "$AWS_REGION" 2>/dev/null || true
          done
          aws ec2 authorize-security-group-ingress --group-id "$ECS_SG_ID" \
            --protocol tcp --port 8001 --source-group "$ALB_SG_ID" --region "$AWS_REGION" 2>/dev/null || true
          aws ec2 authorize-security-group-ingress --group-id "$ECS_SG_ID" \
            --protocol tcp --port 8080 --source-group "$ALB_SG_ID" --region "$AWS_REGION" 2>/dev/null || true

          # Outputs
          echo "vpc_id=${VPC_ID}" >> "$GITHUB_OUTPUT"
          echo "pub_subnet_1=${PUB1}" >> "$GITHUB_OUTPUT"
          echo "pub_subnet_2=${PUB2}" >> "$GITHUB_OUTPUT"
          echo "alb_sg_id=${ALB_SG_ID}" >> "$GITHUB_OUTPUT"
          echo "ecs_sg_id=${ECS_SG_ID}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 3. Secrets Manager ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create secrets
        id: secrets
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          echo "üîê Ensuring secrets exist..."
          SECRET_NAME="${PROJECT_NAME}-${ENVIRONMENT}-secrets"

          if aws secretsmanager describe-secret --secret-id "$SECRET_NAME" --region "$AWS_REGION" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Secret exists: $SECRET_NAME"
            # Update if GROQ_API_KEY is provided
            if [[ -n "${GROQ_API_KEY:-}" ]]; then
              aws secretsmanager update-secret --secret-id "$SECRET_NAME" \
                --secret-string "{\"GROQ_API_KEY\":\"${GROQ_API_KEY}\"}" \
                --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
            fi
          else
            aws secretsmanager create-secret --name "$SECRET_NAME" \
              --description "ShoreExplorer ${ENVIRONMENT} environment secrets" \
              --secret-string "{\"GROQ_API_KEY\":\"${GROQ_API_KEY:-placeholder}\"}" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created secret: $SECRET_NAME"
          fi

          SECRET_ARN=$(aws secretsmanager describe-secret --secret-id "$SECRET_NAME" \
            --query "ARN" --output text --region "$AWS_REGION")
          echo "secret_arn=${SECRET_ARN}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 4. IAM Roles ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create IAM roles
        run: |
          echo "üîë Ensuring IAM roles exist..."
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          SECRET_ARN="${{ steps.secrets.outputs.secret_arn }}"

          TRUST_POLICY='{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"ecs-tasks.amazonaws.com"},"Action":"sts:AssumeRole"}]}'

          # Execution role
          EXEC_ROLE="${APP_NAME}-ecs-task-execution-role"
          if aws iam get-role --role-name "$EXEC_ROLE" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Role exists: $EXEC_ROLE"
          else
            aws iam create-role --role-name "$EXEC_ROLE" --assume-role-policy-document "$TRUST_POLICY" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" --no-cli-pager >/dev/null
            aws iam attach-role-policy --role-name "$EXEC_ROLE" \
              --policy-arn "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
            echo "  ‚úÖ Created role: $EXEC_ROLE"
          fi

          # Execution role inline policies (idempotent put)
          cat > /tmp/exec-policy.json <<POLICY
          {"Version":"2012-10-17","Statement":[
            {"Effect":"Allow","Action":["secretsmanager:GetSecretValue"],"Resource":["arn:aws:secretsmanager:${AWS_REGION}:${ACCOUNT_ID}:secret:${APP_NAME}-secrets*"]},
            {"Effect":"Allow","Action":["logs:CreateLogStream","logs:PutLogEvents","logs:CreateLogGroup"],"Resource":"arn:aws:logs:${AWS_REGION}:${ACCOUNT_ID}:*"}
          ]}
          POLICY
          aws iam put-role-policy --role-name "$EXEC_ROLE" --policy-name "${APP_NAME}-secrets-and-logs" \
            --policy-document file:///tmp/exec-policy.json 2>/dev/null || true

          # Task role
          TASK_ROLE="${APP_NAME}-ecs-task-role"
          if aws iam get-role --role-name "$TASK_ROLE" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Role exists: $TASK_ROLE"
          else
            aws iam create-role --role-name "$TASK_ROLE" --assume-role-policy-document "$TRUST_POLICY" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created role: $TASK_ROLE"
          fi

          # Task role inline policies (idempotent put)
          cat > /tmp/task-policy.json <<POLICY
          {"Version":"2012-10-17","Statement":[
            {"Effect":"Allow","Action":["dynamodb:GetItem","dynamodb:PutItem","dynamodb:UpdateItem","dynamodb:DeleteItem","dynamodb:Query","dynamodb:Scan","dynamodb:DescribeTable"],"Resource":["arn:aws:dynamodb:${AWS_REGION}:${ACCOUNT_ID}:table/${PROJECT_NAME}-${ENVIRONMENT}","arn:aws:dynamodb:${AWS_REGION}:${ACCOUNT_ID}:table/${PROJECT_NAME}-${ENVIRONMENT}/index/*"]},
            {"Sid":"CloudWatchMetrics","Effect":"Allow","Action":["cloudwatch:PutMetricData"],"Resource":"*","Condition":{"StringEquals":{"cloudwatch:namespace":"${PROJECT_NAME}/${ENVIRONMENT}"}}}
          ]}
          POLICY
          aws iam put-role-policy --role-name "$TASK_ROLE" --policy-name "${APP_NAME}-dynamodb-access" \
            --policy-document file:///tmp/task-policy.json 2>/dev/null || true

      # ‚îÄ‚îÄ 5. DynamoDB Table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create DynamoDB table
        run: |
          echo "üóÑÔ∏è  Ensuring DynamoDB table exists..."
          TABLE_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          if aws dynamodb describe-table --table-name "$TABLE_NAME" --region "$AWS_REGION" &>/dev/null; then
            echo "  ‚è≠Ô∏è  Table exists: $TABLE_NAME"
          else
            aws dynamodb create-table --table-name "$TABLE_NAME" \
              --attribute-definitions \
                AttributeName=PK,AttributeType=S \
                AttributeName=SK,AttributeType=S \
                AttributeName=GSI1PK,AttributeType=S \
                AttributeName=GSI1SK,AttributeType=S \
              --key-schema AttributeName=PK,KeyType=HASH AttributeName=SK,KeyType=RANGE \
              --billing-mode PAY_PER_REQUEST \
              --global-secondary-indexes '[{"IndexName":"GSI1","KeySchema":[{"AttributeName":"GSI1PK","KeyType":"HASH"},{"AttributeName":"GSI1SK","KeyType":"RANGE"}],"Projection":{"ProjectionType":"ALL"}}]' \
              --tags Key=Environment,Value="$ENVIRONMENT" Key=Application,Value=ShoreExplorer Key=ManagedBy,Value=GitHubActions \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚è≥ Waiting for table to become active..."
            aws dynamodb wait table-exists --table-name "$TABLE_NAME" --region "$AWS_REGION"
            echo "  ‚úÖ Created table: $TABLE_NAME"
          fi

      # ‚îÄ‚îÄ 6. ECS Cluster & Log Groups ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ECS cluster and log groups
        run: |
          echo "üöÄ Ensuring ECS cluster and log groups exist..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          CLUSTER="${APP_NAME}-cluster"

          # Log groups
          for LG in "/ecs/${APP_NAME}-backend" "/ecs/${APP_NAME}-frontend"; do
            if aws logs describe-log-groups --log-group-name-prefix "$LG" --region "$AWS_REGION" \
              --query "logGroups[?logGroupName=='$LG']" --output text | grep -q "$LG"; then
              echo "  ‚è≠Ô∏è  Log group exists: $LG"
            else
              aws logs create-log-group --log-group-name "$LG" --region "$AWS_REGION" \
                --tags Project="$PROJECT_NAME",Environment="$ENVIRONMENT"
              echo "  ‚úÖ Created log group: $LG"
            fi
            aws logs put-retention-policy --log-group-name "$LG" --retention-in-days 14 --region "$AWS_REGION" 2>/dev/null || true
          done

          # Cluster
          CLUSTER_STATUS=$(aws ecs describe-clusters --clusters "$CLUSTER" --region "$AWS_REGION" \
            --query "clusters[0].status" --output text 2>/dev/null || echo "MISSING")
          if [[ "$CLUSTER_STATUS" == "ACTIVE" ]]; then
            echo "  ‚è≠Ô∏è  Cluster exists: $CLUSTER"
          else
            aws ecs create-cluster --cluster-name "$CLUSTER" \
              --capacity-providers FARGATE \
              --default-capacity-provider-strategy capacityProvider=FARGATE,weight=1 \
              --settings '[{"name":"containerInsights","value":"disabled"}]' \
              --tags key=Project,value="$PROJECT_NAME" key=Environment,value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created cluster: $CLUSTER"
          fi

      # ‚îÄ‚îÄ 7. ALB & Target Groups ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create ALB and target groups
        id: alb
        run: |
          echo "‚öñÔ∏è  Ensuring ALB and target groups exist..."
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          ALB_NAME="${APP_NAME}-alb"
          VPC_ID="${{ steps.networking.outputs.vpc_id }}"
          PUB1="${{ steps.networking.outputs.pub_subnet_1 }}"
          PUB2="${{ steps.networking.outputs.pub_subnet_2 }}"
          ALB_SG="${{ steps.networking.outputs.alb_sg_id }}"

          # ALB
          ALB_ARN=$(aws elbv2 describe-load-balancers --names "$ALB_NAME" \
            --query "LoadBalancers[0].LoadBalancerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "None")

          if [[ "$ALB_ARN" == "None" || -z "$ALB_ARN" ]]; then
            ALB_ARN=$(aws elbv2 create-load-balancer --name "$ALB_NAME" \
              --subnets "$PUB1" "$PUB2" --security-groups "$ALB_SG" \
              --scheme internet-facing --type application --ip-address-type ipv4 \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "LoadBalancers[0].LoadBalancerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created ALB: $ALB_NAME"
          else
            echo "  ‚è≠Ô∏è  ALB exists: $ALB_NAME"
          fi

          ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns "$ALB_ARN" \
            --query "LoadBalancers[0].DNSName" --output text --region "$AWS_REGION")

          # Target Groups
          create_tg() {
            local TG_NAME="$1" PORT="$2" HEALTH="$3"
            local TG_ARN
            TG_ARN=$(aws elbv2 describe-target-groups --names "$TG_NAME" \
              --query "TargetGroups[0].TargetGroupArn" --output text \
              --region "$AWS_REGION" 2>/dev/null || echo "None")
            if [[ "$TG_ARN" == "None" || -z "$TG_ARN" ]]; then
              TG_ARN=$(aws elbv2 create-target-group --name "$TG_NAME" \
                --protocol HTTP --port "$PORT" --vpc-id "$VPC_ID" --target-type ip \
                --health-check-protocol HTTP --health-check-path "$HEALTH" \
                --health-check-interval-seconds 30 --health-check-timeout-seconds 10 \
                --healthy-threshold-count 2 --unhealthy-threshold-count 3 --matcher HttpCode=200 \
                --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
                --query "TargetGroups[0].TargetGroupArn" --output text --region "$AWS_REGION")
              echo "  ‚úÖ Created TG: $TG_NAME" >&2
            else
              echo "  ‚è≠Ô∏è  TG exists: $TG_NAME" >&2
            fi
            echo "$TG_ARN"
          }

          BACKEND_TG_ARN=$(create_tg "${APP_NAME}-backend-tg" 8001 "/api/health")
          FRONTEND_TG_ARN=$(create_tg "${APP_NAME}-frontend-tg" 8080 "/")

          # HTTP Listener (port 80) ‚Äî will be converted to redirect later if HTTPS is set up
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn "$ALB_ARN" \
            --query "Listeners[?Port==\`80\`].ListenerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$LISTENER_ARN" || "$LISTENER_ARN" == "None" ]]; then
            LISTENER_ARN=$(aws elbv2 create-listener --load-balancer-arn "$ALB_ARN" \
              --protocol HTTP --port 80 \
              --default-actions Type=forward,TargetGroupArn="$FRONTEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "Listeners[0].ListenerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created HTTP listener"
          else
            echo "  ‚è≠Ô∏è  HTTP listener exists"
          fi

          # Listener rule: /api/* ‚Üí backend
          EXISTING_RULES=$(aws elbv2 describe-rules --listener-arn "$LISTENER_ARN" \
            --query "Rules[?Conditions[?Field=='path-pattern' && Values[0]=='/api/*']].RuleArn" \
            --output text --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$EXISTING_RULES" || "$EXISTING_RULES" == "None" ]]; then
            aws elbv2 create-rule --listener-arn "$LISTENER_ARN" --priority 10 \
              --conditions Field=path-pattern,Values='/api/*' \
              --actions Type=forward,TargetGroupArn="$BACKEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created /api/* listener rule"
          else
            echo "  ‚è≠Ô∏è  /api/* rule exists"
          fi

          echo "alb_arn=${ALB_ARN}" >> "$GITHUB_OUTPUT"
          echo "alb_dns=${ALB_DNS}" >> "$GITHUB_OUTPUT"
          echo "backend_tg_arn=${BACKEND_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "frontend_tg_arn=${FRONTEND_TG_ARN}" >> "$GITHUB_OUTPUT"
          echo "listener_arn=${LISTENER_ARN}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 8. HTTPS Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup HTTPS
        id: https
        env:
          TEST_DOMAIN: ${{ secrets.TEST_DOMAIN || '' }}
        run: |
          echo "üîí Setting up HTTPS..."
          ALB_ARN="${{ steps.alb.outputs.alb_arn }}"
          FRONTEND_TG_ARN="${{ steps.alb.outputs.frontend_tg_arn }}"
          BACKEND_TG_ARN="${{ steps.alb.outputs.backend_tg_arn }}"
          LISTENER_ARN="${{ steps.alb.outputs.listener_arn }}"

          if [[ -z "$TEST_DOMAIN" ]]; then
            echo "  ‚è≠Ô∏è  TEST_DOMAIN not set ‚Äî skipping HTTPS"
            echo "backend_url=http://${{ steps.alb.outputs.alb_dns }}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          FULL_DOMAIN="test.${TEST_DOMAIN}"

          # Find existing wildcard certificate
          CERT_ARN=$(aws acm list-certificates --region "$AWS_REGION" \
            --query "CertificateSummaryList[?DomainName=='*.${TEST_DOMAIN}' && Status=='ISSUED'].CertificateArn" \
            --output text 2>/dev/null || echo "")

          if [[ -z "$CERT_ARN" || "$CERT_ARN" == "None" ]]; then
            echo "  ‚ö†Ô∏è  No issued wildcard certificate found for *.${TEST_DOMAIN}"
            echo "  Using ALB DNS directly"
            echo "backend_url=http://${{ steps.alb.outputs.alb_dns }}" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "  ‚úÖ Found certificate: $CERT_ARN"

          # HTTPS listener (port 443)
          HTTPS_LISTENER=$(aws elbv2 describe-listeners --load-balancer-arn "$ALB_ARN" \
            --query "Listeners[?Port==\`443\`].ListenerArn" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -z "$HTTPS_LISTENER" || "$HTTPS_LISTENER" == "None" ]]; then
            HTTPS_LISTENER=$(aws elbv2 create-listener --load-balancer-arn "$ALB_ARN" \
              --protocol HTTPS --port 443 --certificates CertificateArn="$CERT_ARN" \
              --ssl-policy ELBSecurityPolicy-TLS13-1-2-2021-06 \
              --default-actions Type=forward,TargetGroupArn="$FRONTEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --query "Listeners[0].ListenerArn" --output text --region "$AWS_REGION")
            echo "  ‚úÖ Created HTTPS listener"

            # Add /api/* rule to HTTPS listener
            aws elbv2 create-rule --listener-arn "$HTTPS_LISTENER" --priority 10 \
              --conditions Field=path-pattern,Values='/api/*' \
              --actions Type=forward,TargetGroupArn="$BACKEND_TG_ARN" \
              --tags Key=Project,Value="$PROJECT_NAME" Key=Environment,Value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ Created HTTPS /api/* rule"
          else
            echo "  ‚è≠Ô∏è  HTTPS listener exists"
            # Ensure correct certificate
            aws elbv2 modify-listener --listener-arn "$HTTPS_LISTENER" \
              --certificates CertificateArn="$CERT_ARN" --region "$AWS_REGION" --no-cli-pager >/dev/null 2>&1 || true
          fi

          # HTTP ‚Üí HTTPS redirect
          CURRENT_ACTION=$(aws elbv2 describe-listeners --listener-arns "$LISTENER_ARN" \
            --region "$AWS_REGION" --query 'Listeners[0].DefaultActions[0].Type' --output text 2>/dev/null || echo "")

          if [[ "$CURRENT_ACTION" != "redirect" ]]; then
            aws elbv2 modify-listener --listener-arn "$LISTENER_ARN" \
              --default-actions 'Type=redirect,RedirectConfig={Protocol=HTTPS,Port=443,StatusCode=HTTP_301}' \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "  ‚úÖ HTTP ‚Üí HTTPS redirect configured"
          else
            echo "  ‚è≠Ô∏è  HTTP redirect already configured"
          fi

          echo "backend_url=https://${FULL_DOMAIN}" >> "$GITHUB_OUTPUT"

      # ‚îÄ‚îÄ 9. DNS Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup DNS
        env:
          TEST_DOMAIN: ${{ secrets.TEST_DOMAIN || '' }}
        run: |
          echo "üåê Setting up DNS..."

          if [[ -z "$TEST_DOMAIN" ]]; then
            echo "  ‚è≠Ô∏è  TEST_DOMAIN not set ‚Äî skipping DNS"
            exit 0
          fi

          FULL_DOMAIN="test.${TEST_DOMAIN}"
          ALB_DNS="${{ steps.alb.outputs.alb_dns }}"
          ALB_NAME="${PROJECT_NAME}-${ENVIRONMENT}-alb"

          # Find hosted zone
          ZONE_ID=$(aws route53 list-hosted-zones-by-name \
            --query "HostedZones[?Name=='${TEST_DOMAIN}.'].Id" \
            --output text 2>/dev/null | cut -d'/' -f3 || echo "")

          if [[ -z "$ZONE_ID" || "$ZONE_ID" == "None" ]]; then
            echo "  ‚ö†Ô∏è  No hosted zone found for ${TEST_DOMAIN} ‚Äî skipping DNS"
            exit 0
          fi

          # Get ALB hosted zone ID
          ALB_ZONE_ID=$(aws elbv2 describe-load-balancers --names "$ALB_NAME" \
            --region "$AWS_REGION" --query "LoadBalancers[0].CanonicalHostedZoneId" --output text 2>/dev/null || echo "")

          if [[ -z "$ALB_ZONE_ID" || "$ALB_ZONE_ID" == "None" ]]; then
            echo "  ‚ö†Ô∏è  Could not get ALB zone ID ‚Äî skipping DNS"
            exit 0
          fi

          # Upsert DNS record
          CHANGE_BATCH=$(cat <<EOF
          {
            "Changes": [{
              "Action": "UPSERT",
              "ResourceRecordSet": {
                "Name": "${FULL_DOMAIN}",
                "Type": "A",
                "AliasTarget": {
                  "HostedZoneId": "${ALB_ZONE_ID}",
                  "DNSName": "${ALB_DNS}",
                  "EvaluateTargetHealth": false
                }
              }
            }]
          }
          EOF
          )

          aws route53 change-resource-record-sets --hosted-zone-id "$ZONE_ID" \
            --change-batch "$CHANGE_BATCH" --no-cli-pager >/dev/null
          echo "  ‚úÖ DNS record set: ${FULL_DOMAIN} ‚Üí ${ALB_DNS}"

      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      #  BUILD & DEPLOY APPLICATION
      # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

      # ‚îÄ‚îÄ 10. Build & Push Images ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push backend image
        run: |
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          docker build \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:${IMAGE_TAG}" \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:${ENVIRONMENT}-latest" \
            -t "${ECR_BASE}/${BACKEND_ECR_REPO}:latest" \
            -f backend/Dockerfile backend/
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:${IMAGE_TAG}"
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:${ENVIRONMENT}-latest"
          docker push "${ECR_BASE}/${BACKEND_ECR_REPO}:latest"

      - name: Build and push frontend image
        run: |
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          IMAGE_TAG="${{ steps.vars.outputs.image_tag }}"
          BACKEND_URL="${{ steps.https.outputs.backend_url }}"

          # Fallback if HTTPS step didn't set backend_url
          if [[ -z "$BACKEND_URL" ]]; then
            BACKEND_URL="http://${{ steps.alb.outputs.alb_dns }}"
          fi

          docker build \
            --build-arg REACT_APP_BACKEND_URL="${BACKEND_URL}" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:${IMAGE_TAG}" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:${ENVIRONMENT}-latest" \
            -t "${ECR_BASE}/${FRONTEND_ECR_REPO}:latest" \
            -f frontend/Dockerfile frontend/
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:${IMAGE_TAG}"
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:${ENVIRONMENT}-latest"
          docker push "${ECR_BASE}/${FRONTEND_ECR_REPO}:latest"

      # ‚îÄ‚îÄ 11. Register Task Definitions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Register backend task definition
        run: |
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          SECRET_ARN="${{ steps.secrets.outputs.secret_arn }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          EXEC_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-execution-role" \
            --query 'Role.Arn' --output text)
          TASK_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-role" \
            --query 'Role.Arn' --output text)

          aws ecs register-task-definition \
            --family "${APP_NAME}-backend-task" \
            --network-mode awsvpc --requires-compatibilities FARGATE \
            --cpu 256 --memory 512 \
            --execution-role-arn "$EXEC_ROLE_ARN" --task-role-arn "$TASK_ROLE_ARN" \
            --container-definitions "[{
              \"name\": \"backend\",
              \"image\": \"${ECR_BASE}/${BACKEND_ECR_REPO}:latest\",
              \"essential\": true,
              \"portMappings\": [{\"containerPort\": 8001, \"protocol\": \"tcp\"}],
              \"secrets\": [{\"name\": \"GROQ_API_KEY\", \"valueFrom\": \"${SECRET_ARN}:GROQ_API_KEY::\"}],
              \"environment\": [
                {\"name\": \"DYNAMODB_TABLE_NAME\", \"value\": \"${PROJECT_NAME}-${ENVIRONMENT}\"},
                {\"name\": \"AWS_DEFAULT_REGION\", \"value\": \"${AWS_REGION}\"},
                {\"name\": \"ENVIRONMENT\", \"value\": \"${ENVIRONMENT}\"},
                {\"name\": \"ENABLE_CLOUDWATCH_METRICS\", \"value\": \"true\"}
              ],
              \"logConfiguration\": {
                \"logDriver\": \"awslogs\",
                \"options\": {
                  \"awslogs-group\": \"/ecs/${APP_NAME}-backend\",
                  \"awslogs-region\": \"${AWS_REGION}\",
                  \"awslogs-stream-prefix\": \"ecs\"
                }
              },
              \"healthCheck\": {
                \"command\": [\"CMD-SHELL\", \"python -c \\\"import urllib.request; exit(0 if urllib.request.urlopen('http://localhost:8001/api/health').status == 200 else 1)\\\"\"],
                \"interval\": 30, \"timeout\": 10, \"retries\": 3, \"startPeriod\": 60
              }
            }]" \
            --tags "key=Project,value=$PROJECT_NAME" "key=Environment,value=$ENVIRONMENT" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null
          echo "‚úÖ Registered backend task definition"

      - name: Register frontend task definition
        run: |
          ACCOUNT_ID="${{ steps.vars.outputs.account_id }}"
          ECR_BASE="${{ steps.vars.outputs.ecr_base }}"
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"

          EXEC_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-execution-role" \
            --query 'Role.Arn' --output text)
          TASK_ROLE_ARN=$(aws iam get-role --role-name "${APP_NAME}-ecs-task-role" \
            --query 'Role.Arn' --output text)

          aws ecs register-task-definition \
            --family "${APP_NAME}-frontend-task" \
            --network-mode awsvpc --requires-compatibilities FARGATE \
            --cpu 256 --memory 512 \
            --execution-role-arn "$EXEC_ROLE_ARN" --task-role-arn "$TASK_ROLE_ARN" \
            --container-definitions "[{
              \"name\": \"frontend\",
              \"image\": \"${ECR_BASE}/${FRONTEND_ECR_REPO}:latest\",
              \"essential\": true,
              \"portMappings\": [{\"containerPort\": 8080, \"protocol\": \"tcp\"}],
              \"logConfiguration\": {
                \"logDriver\": \"awslogs\",
                \"options\": {
                  \"awslogs-group\": \"/ecs/${APP_NAME}-frontend\",
                  \"awslogs-region\": \"${AWS_REGION}\",
                  \"awslogs-stream-prefix\": \"ecs\"
                }
              },
              \"healthCheck\": {
                \"command\": [\"CMD-SHELL\", \"wget --quiet --tries=1 --spider http://localhost:8080/ || exit 1\"],
                \"interval\": 30, \"timeout\": 5, \"retries\": 3, \"startPeriod\": 30
              }
            }]" \
            --tags "key=Project,value=$PROJECT_NAME" "key=Environment,value=$ENVIRONMENT" \
            --region "$AWS_REGION" --no-cli-pager >/dev/null
          echo "‚úÖ Registered frontend task definition"

      # ‚îÄ‚îÄ 12. Create/Update ECS Services ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Create or update ECS services
        run: |
          APP_NAME="${PROJECT_NAME}-${ENVIRONMENT}"
          CLUSTER="${APP_NAME}-cluster"
          ECS_SG="${{ steps.networking.outputs.ecs_sg_id }}"
          PUB1="${{ steps.networking.outputs.pub_subnet_1 }}"
          PUB2="${{ steps.networking.outputs.pub_subnet_2 }}"
          BACKEND_TG="${{ steps.alb.outputs.backend_tg_arn }}"
          FRONTEND_TG="${{ steps.alb.outputs.frontend_tg_arn }}"

          # Backend service
          EXISTING=$(aws ecs describe-services --cluster "$CLUSTER" --services "${APP_NAME}-backend" \
            --query "services[?status=='ACTIVE'].serviceName" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -n "$EXISTING" && "$EXISTING" != "None" ]]; then
            aws ecs update-service --cluster "$CLUSTER" --service "${APP_NAME}-backend" \
              --task-definition "${APP_NAME}-backend-task" --desired-count 1 --force-new-deployment \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "‚úÖ Updated backend service"
          else
            aws ecs create-service --cluster "$CLUSTER" --service-name "${APP_NAME}-backend" \
              --task-definition "${APP_NAME}-backend-task" --desired-count 1 --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[$PUB1,$PUB2],securityGroups=[$ECS_SG],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=$BACKEND_TG,containerName=backend,containerPort=8001" \
              --health-check-grace-period-seconds 120 \
              --deployment-configuration "maximumPercent=200,minimumHealthyPercent=100" \
              --tags key=Project,value="$PROJECT_NAME" key=Environment,value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "‚úÖ Created backend service"
          fi

          # Frontend service
          EXISTING=$(aws ecs describe-services --cluster "$CLUSTER" --services "${APP_NAME}-frontend" \
            --query "services[?status=='ACTIVE'].serviceName" --output text \
            --region "$AWS_REGION" 2>/dev/null || echo "")

          if [[ -n "$EXISTING" && "$EXISTING" != "None" ]]; then
            aws ecs update-service --cluster "$CLUSTER" --service "${APP_NAME}-frontend" \
              --task-definition "${APP_NAME}-frontend-task" --desired-count 1 --force-new-deployment \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "‚úÖ Updated frontend service"
          else
            aws ecs create-service --cluster "$CLUSTER" --service-name "${APP_NAME}-frontend" \
              --task-definition "${APP_NAME}-frontend-task" --desired-count 1 --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[$PUB1,$PUB2],securityGroups=[$ECS_SG],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=$FRONTEND_TG,containerName=frontend,containerPort=8080" \
              --health-check-grace-period-seconds 60 \
              --deployment-configuration "maximumPercent=200,minimumHealthyPercent=100" \
              --tags key=Project,value="$PROJECT_NAME" key=Environment,value="$ENVIRONMENT" \
              --region "$AWS_REGION" --no-cli-pager >/dev/null
            echo "‚úÖ Created frontend service"
          fi

      # ‚îÄ‚îÄ 13. Wait for Stability ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Wait for deployment to stabilize
        run: |
          echo "Waiting for services to stabilize (up to 10 minutes)..."
          CLUSTER="${PROJECT_NAME}-${ENVIRONMENT}-cluster"
          SERVICES=(
            "${PROJECT_NAME}-${ENVIRONMENT}-backend"
            "${PROJECT_NAME}-${ENVIRONMENT}-frontend"
          )
          MAX_WAIT=600
          POLL_INTERVAL=15
          elapsed=0

          while [[ $elapsed -lt $MAX_WAIT ]]; do
            all_stable=true
            for svc in "${SERVICES[@]}"; do
              svc_info=$(aws ecs describe-services \
                --cluster "$CLUSTER" --services "$svc" --region "$AWS_REGION" \
                --query "services[0].{active: length(deployments[?status!='INACTIVE']), running: runningCount, desired: desiredCount}" \
                --output json 2>/dev/null || echo '{"active":0,"running":0,"desired":1}')
              active=$(echo "$svc_info" | jq -r '.active')
              running=$(echo "$svc_info" | jq -r '.running')
              desired=$(echo "$svc_info" | jq -r '.desired')
              echo "${svc}: active_deployments=${active}, running=${running}, desired=${desired}"
              if [[ "$active" != "1" || "$running" != "$desired" ]]; then
                all_stable=false
              fi
            done

            if $all_stable; then
              echo "‚úÖ All services stable!"
              break
            fi

            sleep $POLL_INTERVAL
            elapsed=$((elapsed + POLL_INTERVAL))
          done

          if [[ $elapsed -ge $MAX_WAIT ]]; then
            echo "‚ùå Timed out after ${MAX_WAIT}s waiting for services to stabilize"
            exit 1
          fi

      # ‚îÄ‚îÄ 14. Monitoring ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Setup monitoring
        env:
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL || '' }}
        run: |
          chmod +x infra/aws/scripts/10-setup-monitoring.sh
          bash infra/aws/scripts/10-setup-monitoring.sh "${ENVIRONMENT}"
        continue-on-error: true

      # ‚îÄ‚îÄ 15. Smoke Test ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Run smoke test
        run: |
          BACKEND_URL="${{ steps.https.outputs.backend_url }}"
          if [[ -z "$BACKEND_URL" ]]; then
            BACKEND_URL="http://${{ steps.alb.outputs.alb_dns }}"
          fi

          echo "Running smoke tests against ${BACKEND_URL}"
          sleep 30

          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${BACKEND_URL}/api/health" --max-time 30 || echo "000")

          if [[ "$HTTP_CODE" == "200" ]]; then
            echo "‚úÖ Health check passed (HTTP $HTTP_CODE)"
          else
            echo "‚ö†Ô∏è  Health check returned HTTP $HTTP_CODE (may still be starting)"
          fi

          FRONTEND_URL="${BACKEND_URL%/api*}"
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${FRONTEND_URL}/" --max-time 30 || echo "000")

          if [[ "$HTTP_CODE" == "200" ]]; then
            echo "‚úÖ Frontend accessible (HTTP $HTTP_CODE)"
          else
            echo "‚ö†Ô∏è  Frontend returned HTTP $HTTP_CODE (may still be starting)"
          fi

      # ‚îÄ‚îÄ Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Deployment summary
        if: always()
        run: |
          BACKEND_URL="${{ steps.https.outputs.backend_url }}"
          if [[ -z "$BACKEND_URL" ]]; then
            BACKEND_URL="http://${{ steps.alb.outputs.alb_dns }}"
          fi

          echo "## Test Environment Setup & Deploy Summary" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "| Item | Value |" >> "$GITHUB_STEP_SUMMARY"
          echo "|------|-------|" >> "$GITHUB_STEP_SUMMARY"
          echo "| Environment | \`test\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Image Tag | \`${{ steps.vars.outputs.image_tag }}\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| Commit | \`${{ github.sha }}\` |" >> "$GITHUB_STEP_SUMMARY"
          echo "| App URL | ${BACKEND_URL} |" >> "$GITHUB_STEP_SUMMARY"
          echo "| API Health | ${BACKEND_URL}/api/health |" >> "$GITHUB_STEP_SUMMARY"
          DASHBOARD_URL="https://${AWS_REGION}.console.aws.amazon.com/cloudwatch/home?region=${AWS_REGION}#dashboards:name=${PROJECT_NAME}-${ENVIRONMENT}-dashboard"
          echo "| Dashboard | [CloudWatch](${DASHBOARD_URL}) |" >> "$GITHUB_STEP_SUMMARY"
